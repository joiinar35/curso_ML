{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e462ec7c",
   "metadata": {},
   "source": [
    "# Estimación del Egreso de Estudiantes de Ingeniería en función de los créditos acumulados a los tres años de su ingreso \n",
    "<h2> Generaciones (2000 - 2005)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f49e0",
   "metadata": {},
   "source": [
    "<h2>Tabla de Contenido</h2>\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ul>\n",
    "        <li><a href=\"obj\">Objetivo</a></li>\n",
    "        <li><a href=\"conex\">Conexión a la Base de Datos</a></li>\n",
    "        <li><a href=\"list\">Como listar las Tablas y su Esquema en una Base SQLite3</a></li>\n",
    "        <li><a href=\"query\">Formulación de Consultas SQL</a></li>\n",
    "        <li><a href=\"data\">Preparando los Datos de Entrada</a></li>\n",
    "        <li><a href=\"model\">Creación del modelo de Regresión Logística</a></li>\n",
    "        <li><a href=\"eval\">Evaluación de la Performance del Regresor</a></li>\n",
    "        <li><a href=\"fin\">Conclusiones</a></li>\n",
    "    </ul>\n",
    "    <p>\n",
    "        Tiempo estimado: <strong>90 min</strong>\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4996e621",
   "metadata": {},
   "source": [
    "<h2 id=obj>Objetivo</h2>\n",
    "\n",
    "En este notebook desarrollaremos un modelo de regresion logistica para estimar la probabilidad de egreso de estudiantes de las carreras de Ingeniería Civil, Mecánica, Producción, Naval, Eléctrica y Computación.\n",
    "La idea aqui es concetar con una base de datos SQLite 3 con datos de estudiantes de las generaciones 2000 a 2005 inclusive.\n",
    "Se generará una consulta SQL para extraer los datos de las tablas de la base y luego se importaran los datos en un dataframe.\n",
    "La idea del trabajo es predecir si un estudiante egresara o no en función de los creditos ganados a los tres años de ingresos. \n",
    "Teóricamente un estudiante ideal deberia avanzar ganando 75 creditos al año para estar siempre al día y poder egresar a los 5 años. En la realidad los estudiantes egresan en poco mas de 8 años en promedio según datos de eficiencia de egreso 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d46daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los paquetes por defecto\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be542ba1",
   "metadata": {},
   "source": [
    "<h2 id=conex>Conexión a la Base de Datos</h2>\n",
    "\n",
    "Ahora creamos una conexion a la base de datos <code>ingenieria.db</code>.\n",
    "\n",
    "**Nota:** Aqui tenemos que tener presente donde tenemos el archivo ingenieria.db porque pueden dar un path absoluto  o relativo al archivo. Para saber que notacion uisar les dejo la url de la seccion referente a database paths notation en el manual de create_engine().\n",
    "\n",
    "https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls\n",
    "\n",
    "Yo voy a asumir que tengo el archivo <code>ingenieria.db</code> en el mismo directorio de trabajo del notebook. asi que usare tres slashes ///\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a4678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "# Reemplaza 'tu_base_de_datos.db' con la ruta a tu archivo SQLite\n",
    "engine = create_engine('sqlite:///ingenieria.db?charset=utf8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ee27e",
   "metadata": {},
   "source": [
    "<h2 id=list>Como listar las Tablas y su Esquema en una Base SQLite3</h2>\n",
    "\n",
    "Una vez creada la conexion es necesario saber que tablas hay y como es el esquema de cada una para poder realizar consultas. Esto se hace a travez del <code>inspector</code>\n",
    "En la celda de abajo se da el codigo para realizar estas dos tareas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c739483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para ver las tablas que hay en la base\n",
    "\n",
    "inspector = inspect(engine)\n",
    "\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "\n",
    "possible_encodings = ['latin-1', 'cp1252', 'iso-8859-15']\n",
    "\n",
    "\n",
    "print(\"Tablas en la base de datos:\")\n",
    "for table_name in table_names:\n",
    "    print(f\"- {table_name}\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f220c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cierro la conexion y libero el recurso\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52ba81",
   "metadata": {},
   "source": [
    "Esta base tiene algunos caracteres no UTF-8 asi que puede dar error en cualquier nombre de campo, tabla o registro (diresis, tildes, apostrofes etc, todo eso da error si no se decodifica correctamente)\n",
    "Para eso casos pueden probar algo como esto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e092348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo una funcion para lidiar con las distintas codificaciones que pueda haber\n",
    "\n",
    "def safe_decode(text, encodings):\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            return text.encode(enc).decode('utf-8')\n",
    "        except UnicodeEncodeError:\n",
    "            pass\n",
    "        except UnicodeDecodeError:\n",
    "            pass\n",
    "    return text  # Si no se puede decodificar, devuelve el texto original\n",
    "\n",
    "\n",
    "\n",
    "print(\"Nombres de las tablas:\")\n",
    "\n",
    "for table_name in table_names:\n",
    "    decoded_name = safe_decode(table_name, possible_encodings)\n",
    "    print(f\"- Original: {table_name}, Decodificado: {decoded_name}\")\n",
    "    columns = inspector.get_columns(table_name)\n",
    "    for column in columns:\n",
    "        column_name = column['name']\n",
    "        decoded_column_name = safe_decode(column_name, possible_encodings)\n",
    "        print(f\"  - Original: {column_name}, Decodificado: {decoded_column_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8975d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para saber el esquema de las tablas\n",
    "#coding: utf-8\n",
    "\n",
    "print(\"Esquemas de las tablas:\")\n",
    "for table_name in table_names:\n",
    "    print(f\"\\nEsquema de la tabla: {table_name}\")\n",
    "    columns = inspector.get_columns(table_name)\n",
    "    for column in columns:\n",
    "        print(f\"  - Nombre: {column['name']}\")\n",
    "        print(f\"    Tipo: {column['type']}\")\n",
    "        print(f\"    Nulable: {column['nullable']}\")\n",
    "        print(f\"    Clave Primaria: {column['primary_key']}\")\n",
    "        if 'default' in column:\n",
    "            print(f\"    Valor por defecto: {column['default']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa54c7",
   "metadata": {},
   "source": [
    "<h2 id=query>Formulación de Consultas SQL</h2>\n",
    "\n",
    "Despues de inspeccionar las tablas de la base y sus relaciones, estamos en condiciones de crear un par de consultas SQL a la Base de Datos para definir el dataset inicial de trabajo.\n",
    "\n",
    "1) Listado de Alumnos que ingresaron a las carreras de ingenieria Civil, Mecánica, Naval, Eléctrica , Producción y Computación entre 2000 y 2005 inclusive.\n",
    "\n",
    "2) Hallar los créditos acumulados a los 2.5 años de ingreso para cada uno\n",
    "\n",
    "3) Crear un Dataframe que contenga las siguientes columnas: Id, Carrera, Ciclo, Generacion, Creds2a, FechaEgreso\n",
    "\n",
    "Esta son consultas complejas porque la vieja base del SGB de Ingeniería era muy desordenada y requería agregar diversas condiciones para filtrar casos atípicos. Por esta razón yo les proporcionaré las consultas ya preparadas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332ab31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lleno un tabla temporal con las cedulas de los ingresos entre 2005 y 2009 a las carreras en cuestion\n",
    "# aqui se tamizan los casos atipicos, cambios de plan etc. Queremos ingresos puros no estudiantes\n",
    "# de generaciones anteriores\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    rs = conn.execute('delete from temporal')\n",
    "    conn.close()\n",
    "\n",
    "query1 = 'insert into temporal select distinct cedula from estudcarr where generacion between 2005 and 2009 \\\n",
    "        and carrera in (22, 72)' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef553d1e",
   "metadata": {},
   "source": [
    "Chequeamos que la tabla temporal se haya poblado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71641af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lleno la tabla tremporal con las cedulas deseadas\n",
    "# Vean que aqui estoy haciendo una operacion en la propia base de datos asi que no tengo necesidad de extraer el\n",
    "# resultado de la operacion a un dataframe. Por eso uso la sintaxis tradicional con `with`\n",
    "with engine.connect() as conn:\n",
    "    rs = conn.execute(query1)\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420bf537",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186001f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chequeo que los datos hayan sido cargados y saco alguna info basica del nro de registros, tipos etc.\n",
    "\n",
    "df = pd.read_sql_query('select * from temporal', engine)\n",
    "\n",
    "df.info()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79279d",
   "metadata": {},
   "source": [
    "Una vez preparados los datos de las generaciones hago un aconsulta para saber los créditos a dos años de haber empezado cada alumno de cada carrera. Pueden ver que no hay inner joins indicados, PERO si es un inner join de tres tablas. En la notacion explicita deberia haber invocado inner join cada dos tablas que cruzo, pero porque no lo hice aqui?\n",
    "\n",
    "La consulta anidada se debe a que hay alumnos que hacen mas de una carrera (para saltearse las previaturas), entonces convenimos en elegir la carrera y ciclo donde tienen la mayor cantidad de creditos ganados. La idea es estudiar estudiantes \"puros\" o sea que hagan una sola carrera para reducir sesgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc422a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saco la suma de créditos a los tres años de haber empezado.\n",
    "\n",
    "query2 = 'select * from (select s.cedula as \"cedula\", u.carrera as \"carrera\", u.ciclo as \"ciclo\", sum(creditos) as \"Creds3a\", \\\n",
    "Fechaing from activ2 s, asigcarr t, estudcarr u \\\n",
    "where s.cedula = u.cedula and t.carrera = u.carrera and t.ciclo = u.ciclo and t.carrera in (22, 72) and \\\n",
    "s.asignatura= t.asignatura and tipoactividad in (\"E\", \"R\") and nota > 2 and fecha between Fechaing and \\\n",
    "Fechaing + 30300 and s.cedula in temporal \\\n",
    "group by u.cedula, u.carrera, u.ciclo) group by cedula having(max(Creds3a))'\n",
    "\n",
    "\n",
    "df = pd.read_sql_query(query2, engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a10db8",
   "metadata": {},
   "source": [
    "Inspeccionamos la salida de la consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa66116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos las primeras 10 filas\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82108540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos informacion sobre los creditos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa381f",
   "metadata": {},
   "source": [
    "Podemos crear un histograma con la ditribucion de creditos, lo saco mediante Matplotlib y mediante Seaborn\n",
    "vean las diferencias de cada notacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d093d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Creds3a'], bins=45, range=(0, 350))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una version mas linda del histograma con seaborn\n",
    "\n",
    "sns.histplot(df['Creds3a'], bins = 45, binrange=(0, 350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saco estadisticas del dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae61d16",
   "metadata": {},
   "source": [
    "#### Exploración de los Datos Obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5448c991",
   "metadata": {},
   "source": [
    "Podemos realizar un EDA basico mediante un boxplot de la salida de la consulta por carrera y ciclo. Como carrera y ciclo son dos categorias dferentes y tengo que agrupar en la combinacion de ambas debo crear una nva columna en el Dataframe llamada carrera-ciclo y agrupar sobre ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6123fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo la columna carrera-ciclo\n",
    "df['carrera_ciclo'] = df['carrera'].astype(str) + '-' + df['ciclo'].astype(str)\n",
    "\n",
    "\n",
    "sns.boxplot(data=df, x=\"carrera_ciclo\", y=\"Creds3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07443dbb",
   "metadata": {},
   "source": [
    "Hacemos los mismo pero con la foto a 6 años de Ingresado, para control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c25657",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = 'select * from (select s.cedula as \"cedula\", u.carrera as \"carrera\", u.ciclo as \"ciclo\", \\\n",
    "sum(creditos) as \"Creds6a\", Fechaing, Fechaegr from activ2 s, asigcarr t, estudcarr u \\\n",
    "where s.cedula = u.cedula and t.carrera = u.carrera and t.ciclo = u.ciclo and t.carrera in (22, 72) and \\\n",
    "s.asignatura= t.asignatura and tipoactividad in (\"E\", \"R\") and nota > 2 and fecha between Fechaing and \\\n",
    "Fechaing + 60300 and s.cedula in temporal \\\n",
    "group by u.cedula, u.carrera, u.ciclo) group by cedula having(max(Creds6a))'\n",
    "\n",
    "\n",
    "df2 = pd.read_sql_query(query3, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d272301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos informacion sobre los creditos\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a118b2d5",
   "metadata": {},
   "source": [
    "Visualizamos los resultados\n",
    "con otro histograma y boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d51576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma de creditos a los 6 anios de ingreso\n",
    "\n",
    "sns.histplot(df2['Creds6a'], bins = 45, binrange=(0, 450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f5427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo la columna carrera-ciclo en Df2\n",
    "df2['carrera_ciclo'] = df2['carrera'].astype(str) + '-' + df2['ciclo'].astype(str)\n",
    "\n",
    "\n",
    "sns.boxplot(data=df2, x=\"carrera_ciclo\", y=\"Creds6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619f22a",
   "metadata": {},
   "source": [
    "<h2 id=data>Preparando los Datos de Entrada</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c9de4",
   "metadata": {},
   "source": [
    "Ahora debo realizar una ultima consulta para ver quienes egresaron a los 6 anios de las generaciones involucradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a527bf",
   "metadata": {},
   "source": [
    "Debo cambiar el tipo de la columna Fechaegr a \"int32\" porque aparece como \"object\" o sea como strings. Ademas debo recodificar Fechaegr como: 0 - No egresado, 1- egresado usando label encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.replace({'Fechaegr': \"\"}, {'Fechaegr': '0'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e0e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Fechaegr']=df2['Fechaegr'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4265020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df2['Fechaegr'] > 0, 'Fechaegr']=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90eaca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b0edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombro la columna \"Fechaegr\" a \"Egresa\"\n",
    "df2.rename(columns={'Fechaegr': 'Egresa'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f4d7a6",
   "metadata": {},
   "source": [
    "Preparo el dataset de trabajo: concateno df2 y df['Creds3a'] como entrada para el modelo. Tb debo agregar ceros en los casos de alumnos que no obtuvieron creditos en los primeros 3 años y que luego a los 6 ya tienen algo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eaef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('cedula', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e525b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.set_index('cedula', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d324ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ing = pd.concat([df2, df['Creds3a']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b86a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ing.head(30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3757e297",
   "metadata": {},
   "source": [
    "En el caso de alumnos que no generaron creditos en los primeros 3 anios el concatenamiento les asigno NaN por defecto en la columna 'Creds3a', debemos reemplazar los NaN por un valor numerico (0 en este caso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c0d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ing.replace({'Creds3a': np.NaN}, {'Creds3a': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fe8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ing.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f793d3",
   "metadata": {},
   "source": [
    "Tambien debo cambiar el tipo de los datos de la columna \"Creds3a\" de \"object\" a \"int32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e5dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ing['Creds3a']=data_ing['Creds3a'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d1a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checo los tipos de las columnas en el dataframe de trabajo.\n",
    "data_ing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8416410",
   "metadata": {},
   "source": [
    "<h2 id=model>Creación del modelo de Regresión Logística</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2755f8",
   "metadata": {},
   "source": [
    "#### - Identificamos la columna objetivo y las caracteristicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5434db",
   "metadata": {},
   "source": [
    "Primero Identificamos la variable objetivo (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c061074",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_ing['Egresa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d4a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=data_ing[['carrera', 'ciclo', 'Creds3a', 'Creds6a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdbfbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos la biblioteca sklearn y las funcionalidades de regresion logistica\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54014fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.values\n",
    "y = target.values\n",
    "\n",
    "\n",
    "#1- Dataset Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(\"Original shape: \", X_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#4- Make predictions on the test dataset.\n",
    "y_pred = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0034f21",
   "metadata": {},
   "source": [
    "<h2 id=eval>Evaluación de la Performance del Regresor</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b9da6",
   "metadata": {},
   "source": [
    "Evaluaremos la performance del regresor para el dataset de testing a traves de las métricas ya vistas en el curso.\n",
    "Si bien calcularemos todas las metricas usuales nos guiaremos por el score F1 el cual es la media armonina entre la precision y el recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b5a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tp = cm[1, 1]  # True Positives\n",
    "fp = cm[0, 1]  # False Positives\n",
    "fn = cm[1, 0]  # False Negatives\n",
    "tn = cm[0, 0]  # True Negatives\n",
    "\n",
    "# Accuracy\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "# Precision\n",
    "precision = tp / (tp + fp)\n",
    "# Recall\n",
    "recall = tp / (tp + fn)\n",
    "# Specificity\n",
    "specificity = tn / (tn + fp)\n",
    "# F1 Score\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('Specificity:', specificity)\n",
    "print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee088dc",
   "metadata": {},
   "source": [
    "Podemos Plotear la matriz de confusión tal como lo vimos en las slides. \n",
    "Como ejercicio les dejo de ejercicio hacer el grafico de la matriz de confusion en colores tal como aparece en el notebook \"ML0101EN-Clas-SVM-cancer.ipyn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9e4c5",
   "metadata": {},
   "source": [
    "Hagamos algunas predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e8cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval=features.sample(10).values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd7e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_eval)\n",
    "print(X_eval, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb6ba6",
   "metadata": {},
   "source": [
    "## Validación del Modelo\n",
    "Genial, hemos creado un modelo de regresion logistica, lo hemos entrenado y hemos validado su preformance con el conjunto de datos de testing. También hemos calculado las metricas para evaluar la bondad del modelo.\n",
    "Ahora la gran pregunta, el modelo esta validado?\n",
    "\n",
    "Podriamos sentirnos tentados a decir que si ya que el F1 score de 0.78 no es mal valor. Pero en general solo podemos decir que el modelo es bueno. que predice aceptablemnte si un estudiante egresará en función de los créditos ganados a los 3 años.\n",
    "\n",
    "Una forma mas profesional de validar el Modelo seria calcular el F1 score para prediciones hechas con un conjunto de datos completamente direferente del de test y ver que pasa.\n",
    "\n",
    "En caso que los valores de F1 se mantengan cercanos podremos decir que el modelo es relativamente robusto.Y en caso negativo deberíamos evaluar otras posibilidades, las cuales les dejo para pensar.\n",
    "\n",
    "Otra posibilidad es usr la columns creditos a 6 años  junto con creditos a 3 años como caracteristica a ver si metiendo esta otra columna y repitinedo todos los pasos anteriores mejora la performance. (lo dejo como ejercicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    rs = conn.execute('delete from temporal')\n",
    "    conn.close()\n",
    "\n",
    "query4 = 'insert into temporal select distinct cedula from estudcarr where generacion between 2010 and 2012 \\\n",
    "        and carrera in (22, 72)' \n",
    "\n",
    "# Lleno la tabla tremporal con las cedulas deseadas\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    rs = conn.execute(query1)\n",
    "    conn.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nvamente Saco la suma de créditos a los tres años de haber empezado.\n",
    "\n",
    "query2 = 'select * from (select s.cedula as \"cedula\", u.carrera as \"carrera\", u.ciclo as \"ciclo\", sum(creditos) as \"Creds3a\", \\\n",
    "Fechaing from activ2 s, asigcarr t, estudcarr u \\\n",
    "where s.cedula = u.cedula and t.carrera = u.carrera and t.ciclo = u.ciclo and t.carrera in (22, 72) and \\\n",
    "s.asignatura= t.asignatura and tipoactividad in (\"E\", \"R\") and nota > 2 and fecha between Fechaing and \\\n",
    "Fechaing + 30300 and s.cedula in temporal \\\n",
    "group by u.cedula, u.carrera, u.ciclo) group by cedula having(max(Creds3a))'\n",
    "\n",
    "\n",
    "df = pd.read_sql_query(query2, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52c890",
   "metadata": {},
   "source": [
    "Ejercicio: Rehacer todos los comandos a partir de la exploracion de datos y Preparando los datos de entrada  con este nvo dataset hacer predicciones y calcular las metricas en especial F1 (No crear el modelo , ni entrenarlo porque ya lo esta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a871d8aa",
   "metadata": {},
   "source": [
    "<h2 id=fin>Conclusiones</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59387064",
   "metadata": {},
   "source": [
    "Felicitaciones! han llegado al final de este ejercicio, espreo que les haya servido para repasar algunso conceptos que vimos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0736e31",
   "metadata": {},
   "source": [
    "### Autor\n",
    "\n",
    "<a href='https://www.linkedin.com/in/ram%C3%B3n-c-4389b6b/' >Ram&oacute;n Caraballo</a> Abril 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a5b8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
